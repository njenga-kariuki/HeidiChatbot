// types.ts
export interface AdviceEntry {
  category: string;
  subCategory: string;
  content: string;
  context: string;
  sourceTitle: string;
  sourceLink: string;
}

export interface VectorSearchResult {
  entry: AdviceEntry;
  similarity: number;
}

// dataLoader.ts
import { parse } from 'papaparse';
import fs from 'fs';
import { AdviceEntry } from './types';

export class DataLoader {
  private static instance: DataLoader;
  private adviceData: AdviceEntry[] = [];

  private constructor() {}

  public static getInstance(): DataLoader {
    if (!DataLoader.instance) {
      DataLoader.instance = new DataLoader();
    }
    return DataLoader.instance;
  }

  public async loadData(filePath: string): Promise<void> {
    try {
      const csvData = fs.readFileSync(filePath, 'utf-8');
      const parseResult = parse(csvData, {
        header: true,
        skipEmptyLines: true,
        transform: (value) => value.trim()
      });

      this.adviceData = parseResult.data.map((row: any) => ({
        category: row.Category,
        subCategory: row.SubCategory,
        content: row.Content,
        context: row.Context,
        sourceTitle: row.SourceTitle,
        sourceLink: row.SourceLink
      }));
    } catch (error) {
      throw new Error(`Failed to load advice data: ${error.message}`);
    }
  }

  public getData(): AdviceEntry[] {
    return this.adviceData;
  }
}

// vectorSearch.ts
import { AdviceEntry, VectorSearchResult } from './types';
import { Configuration, OpenAIApi } from 'openai';

export class VectorSearch {
  private openai: OpenAIApi;
  private embeddings: { entry: AdviceEntry; vector: number[] }[] = [];

  constructor(apiKey: string) {
    const configuration = new Configuration({ apiKey });
    this.openai = new OpenAIApi(configuration);
  }

  public async initialize(entries: AdviceEntry[]): Promise<void> {
    for (const entry of entries) {
      const searchText = `${entry.category} ${entry.subCategory} ${entry.content}`;
      const vector = await this.getEmbedding(searchText);
      this.embeddings.push({ entry, vector });
    }
  }

  private async getEmbedding(text: string): Promise<number[]> {
    const response = await this.openai.createEmbedding({
      model: "text-embedding-ada-002",
      input: text
    });
    return response.data.data[0].embedding;
  }

  private cosineSimilarity(a: number[], b: number[]): number {
    const dotProduct = a.reduce((sum, val, i) => sum + val * b[i], 0);
    const magnitudeA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));
    const magnitudeB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));
    return dotProduct / (magnitudeA * magnitudeB);
  }

  public async search(query: string, threshold: number = 0.7): Promise<VectorSearchResult[]> {
    const queryVector = await this.getEmbedding(query);
    
    return this.embeddings
      .map(({ entry, vector }) => ({
        entry,
        similarity: this.cosineSimilarity(queryVector, vector)
      }))
      .filter(result => result.similarity >= threshold)
      .sort((a, b) => b.similarity - a.similarity)
      .slice(0, 5);  // Limit to top 5 results as per requirements
  }
}

// claude.ts
import { Message } from '@shared/schema';
import Anthropic from '@anthropic-ai/sdk';
import { DataLoader } from './dataLoader';
import { VectorSearch } from './vectorSearch';
import { VectorSearchResult } from './types';

if (!process.env.CLAUDE_API_KEY || !process.env.OPENAI_API_KEY) {
  throw new Error('CLAUDE_API_KEY and OPENAI_API_KEY are required');
}

const anthropic = new Anthropic({
  apiKey: process.env.CLAUDE_API_KEY,
});

const vectorSearch = new VectorSearch(process.env.OPENAI_API_KEY);

// Initialize data and vector search
export async function initializeSystem(csvPath: string): Promise<void> {
  const dataLoader = DataLoader.getInstance();
  await dataLoader.loadData(csvPath);
  await vectorSearch.initialize(dataLoader.getData());
}

const STAGE1_SYSTEM_PROMPT = `You are a specialized chatbot that provides startup and entrepreneurship advice based on Heidi Roizen's experiences and insights. Your responses should be drawn exclusively from the provided advice entries.

Response Generation Rules:
1. Data Search Parameters:
   - Use the provided relevant advice points (max 5)
   - Only include highly relevant advice points
   
2. Response Construction:
   - Combine selected advice points into a coherent narrative
   - For each relevant advice point, incorporate ALL associated context
   - When using direct quotes, format as: "As I mentioned in [Source Content Title], '[quote]'"
   - For paraphrased content, integrate naturally while maintaining accuracy
   - If multiple perspectives exist on a topic, frame them as different valid approaches
   - If no relevant advice exists, respond with: "This area hasn't been covered in my existing advice yet."

3. Source Attribution:
   - End each response with: "For more insights, see: [Source Links]"
   - Include all unique source links from utilized advice points
   - Format multiple sources as a bullet list`;

const STAGE2_SYSTEM_PROMPT = `Transform the given response into Heidi Roizen's distinctive communication style while maintaining all factual content and source attributions. Apply these style characteristics:

Key Style Elements:
- Lead with experience-based insight
- Use direct, clear language
- Include phrases like "Look..." or "Here's the thing..." to transition to key points
- Share real-world context without breaking confidentiality
- Balance optimism with pragmatism
- Use rhetorical questions to frame complex issues
- Include specific examples while maintaining privacy
- Acknowledge nuance in complex situations
- Use short sentences for emphasis
- Include personal observations from extensive experience
- Stay professional while being approachable

Guidelines:
- Avoid over-casual language while maintaining conversational tone
- Ground advice in practical experience
- Address the core issue while acknowledging broader context
- Use "I've seen" and "in my experience" to establish authority naturally
- Break down complex topics into digestible insights
- Maintain all source attributions and links from the original response`;

export async function generateStage1Response(query: string): Promise<string> {
  try {
    // Perform vector search
    const searchResults = await vectorSearch.search(query);
    
    if (searchResults.length === 0) {
      return "This area hasn't been covered in my existing advice yet.";
    }

    // Add search results to the prompt
    const contextPrompt = `Based on the following relevant advice entries, provide a comprehensive response:

${searchResults.map((result, index) => `
Entry ${index + 1}:
Category: ${result.entry.category}
SubCategory: ${result.entry.subCategory}
Content: ${result.entry.content}
Context: ${result.entry.context}
Source: ${result.entry.sourceTitle}
Link: ${result.entry.sourceLink}
`).join('\n')}

Query: ${query}`;

    const completion = await anthropic.messages.create({
      model: 'claude-3-opus-20240229',
      max_tokens: 2000,
      temperature: 0.7,
      system: STAGE1_SYSTEM_PROMPT,
      messages: [{ role: 'user', content: contextPrompt }],
    });
    
    return completion.content[0].text;
  } catch (error) {
    throw new Error(`Stage 1 generation failed: ${error.message}`);
  }
}

export async function generateStage2Response(stage1Response: string): Promise<string> {
  try {
    if (!stage1Response || stage1Response.trim() === '') {
      throw new Error('Stage 1 response is empty or invalid');
    }

    const completion = await anthropic.messages.create({
      model: 'claude-3-opus-20240229',
      max_tokens: 2000,
      temperature: 0.7,
      system: STAGE2_SYSTEM_PROMPT,
      messages: [{ role: 'user', content: stage1Response }],
    });
    
    return completion.content[0].text;
  } catch (error) {
    throw new Error(`Stage 2 generation failed: ${error.message}`);
  }
}